{
 "cells": [
  {
   "cell_type": "code",
   "id": "d4c1c87a-2b0f-4202-a209-e4048ecfe9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.156841Z",
     "start_time": "2024-12-04T03:06:37.643063Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, sqlite3\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9df6e1b0ffc2aeb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.162580Z",
     "start_time": "2024-12-04T03:06:38.160718Z"
    }
   },
   "source": [
    "def valid_data(user_log_df, activity_log_df):\n",
    "    intersection = np.intersect1d(user_log_df.columns, activity_log_df.columns)\n",
    "\n",
    "    user_int = user_log_df[intersection]\n",
    "    activity_int = activity_log_df[intersection]\n",
    "\n",
    "    # if the rows, that are common in both data frames do intersect with different data\n",
    "    # the data is deemed invalid and processing cannot continue\n",
    "    return (user_int == activity_int).all(axis=1).all()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "eb4f1774d4a57d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.193655Z",
     "start_time": "2024-12-04T03:06:38.191099Z"
    }
   },
   "source": [
    "def prep_df(dataframes):\n",
    "    if dataframes is None:\n",
    "        gui.set_status(\"No data selected\")\n",
    "        return\n",
    "\n",
    "    user_log_df = next((f for f in dataframes if \"Date\" in f.columns), None)\n",
    "    activity_log_df = next((f for f in dataframes if \"Action\" in f.columns), None)\n",
    "    component_df = next((f for f in dataframes if \"Code\" in f.columns), None)\n",
    "\n",
    "    if user_log_df is None:\n",
    "        gui.set_status(\"User Log Data Not Found\")\n",
    "        return\n",
    "    if activity_log_df is None:\n",
    "        gui.set_status(\"Activity Log Data Not Found\")\n",
    "        return\n",
    "    if component_df is None:\n",
    "        gui.set_status(\"Component Data Not Found\")\n",
    "        return\n",
    "\n",
    "    if not valid_data(user_log_df, activity_log_df):\n",
    "        gui.set_status(\"Data is not valid\")\n",
    "        return\n",
    "    return user_log_df, activity_log_df, component_df"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "12a51e145c0d4cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.200090Z",
     "start_time": "2024-12-04T03:06:38.197466Z"
    }
   },
   "source": [
    "def transformation_remove(user_log_df, activity_log_df, component_df):\n",
    "    # 1. REMOVE: No outputs should include any data from Component: System, and Folder.\n",
    "    delete_col_name = '__delete_row'\n",
    "\n",
    "    # Function to mark rows for deletion based on a condition\n",
    "    def mark_for_deletion(df, cond):\n",
    "        df.loc[cond, delete_col_name] = True\n",
    "        return df\n",
    "\n",
    "    # Mark rows for deletion\n",
    "    condition = (lambda df: (df['Component'] == 'System') | (df['Component'] == 'Folder'))\n",
    "\n",
    "    component_df = mark_for_deletion(component_df, condition(component_df))\n",
    "    activity_log_df = mark_for_deletion(activity_log_df, condition(activity_log_df))\n",
    "\n",
    "    # Propagate deletion from activity_log_df to user_log_df\n",
    "    filtered_indexes = activity_log_df[activity_log_df[delete_col_name] == True].index\n",
    "    user_log_df.loc[filtered_indexes, delete_col_name] = True\n",
    "\n",
    "    # Drop marked rows\n",
    "    def drop_marked_rows(df):\n",
    "        df.drop(df[df[delete_col_name] == True].index, inplace=True)  # Drop rows in place\n",
    "        df.drop(columns=[delete_col_name], inplace=True)  # Drop the marker column in place\n",
    "        df.reset_index(drop=True, inplace=True)  # Reset the index in place\n",
    "\n",
    "    drop_marked_rows(user_log_df)\n",
    "    drop_marked_rows(activity_log_df)\n",
    "    drop_marked_rows(component_df)\n",
    "\n",
    "    return len(user_log_df) != len(activity_log_df)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7cd537a1dcea476b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.205057Z",
     "start_time": "2024-12-04T03:06:38.203454Z"
    }
   },
   "source": [
    "def transformation_rename(user_log_df, activity_log_df):\n",
    "    # 2. RENAME: The column “User Full Name *Anonymized” should be renamed\n",
    "    # as User_ID both in ACTIVITY_LOG and USER_LOG CSVs.\n",
    "    col_name_change = {'User Full Name *Anonymized': 'User_ID'}\n",
    "    activity_log_df.rename(columns=col_name_change, inplace=True)\n",
    "    user_log_df.rename(columns=col_name_change, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "e6c3e80c9ee6369d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.210335Z",
     "start_time": "2024-12-04T03:06:38.208517Z"
    }
   },
   "source": [
    "def transformation_merge(user_log_df, activity_log_df):\n",
    "    # 3. MERGE: Merge the suitable CSVs for analysing user interactions with each component.\n",
    "    df = pd.concat([user_log_df, activity_log_df.drop('User_ID', axis=1)], axis=1)\n",
    "\n",
    "    df['Date'] = (pd.to_datetime(df['Date'], format='%d/%m/%Y %H:%M') +\n",
    "                  pd.to_timedelta(df['Time']))\n",
    "\n",
    "    # Drop the original 'Date' and 'Time' columns if no longer needed\n",
    "    merge_log_df = df.drop(columns=['Time']).rename(columns={'Date': 'Datetime'})\n",
    "    return merge_log_df\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c4e8cda41041508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.215516Z",
     "start_time": "2024-12-04T03:06:38.213735Z"
    }
   },
   "source": [
    "def transformation_reshape(merge_log_df, col_name, period):\n",
    "    # 4. RESHAPE: Reshape the data using pivot operation.\n",
    "\n",
    "    merge_log_df[col_name] = merge_log_df['Datetime'].dt.to_period(period)\n",
    "\n",
    "    pivot_data = merge_log_df.pivot_table(\n",
    "        index=['User_ID', col_name],\n",
    "        columns='Component',\n",
    "        values='Action',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    pivot_data.columns = [col for col in pivot_data.columns]\n",
    "\n",
    "    return pivot_data.reset_index()\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3d52debdfc6ca419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.222104Z",
     "start_time": "2024-12-04T03:06:38.220485Z"
    }
   },
   "source": [
    "def transformation_count(pivot_data, col_name):\n",
    "    # 5. COUNT: The interactions for each user with the Component for each month.\n",
    "    pivot_data['Total Interaction'] = pivot_data.loc[:, ~pivot_data.columns.isin(['User_ID', col_name])].sum(axis=1)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "58242fc047e95dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.231194Z",
     "start_time": "2024-12-04T03:06:38.228860Z"
    }
   },
   "source": [
    "def transformation_output_statistics(pivot_data, period):\n",
    "    #     OUTPUT STATISTICS: Produce the mean, mode and median for the components: Quiz, Lecture, Assignment, Attendance, and Survey.\n",
    "    # - For each month\n",
    "    # - For the entire 13-week academic semester\n",
    "    selected_components = ['User_ID', period, 'Quiz', 'Lecture', 'Assignment', 'Attendence', 'Survey']\n",
    "    columns_in_df = [c for c in selected_components if c in pivot_data.columns]\n",
    "    raw_data = pivot_data[columns_in_df]\n",
    "    monthly_stats = raw_data[['User_ID', period]].copy()\n",
    "    data_df = raw_data.loc[:, ~raw_data.columns.isin(['User_ID', period])]\n",
    "    monthly_stats['Mean'] = data_df.fillna(0).mean(axis=1)\n",
    "    monthly_stats['Median'] = data_df.median(axis=1)\n",
    "    mode = data_df.mode(axis=1)\n",
    "    if not mode.empty:\n",
    "        monthly_stats['Mode'] = mode.iloc[:, 0]\n",
    "    else:\n",
    "        monthly_stats['Mode'] = pd.NA\n",
    "    return monthly_stats\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "27ca46882cef1f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.237104Z",
     "start_time": "2024-12-04T03:06:38.235174Z"
    }
   },
   "source": [
    "def transformation_output_correlation(pivot_data):\n",
    "    correlation_components = ['Assignment', 'Quiz', 'Lecture', 'Book', 'Project', 'Course']\n",
    "    correlation_data = pivot_data[[c for c in correlation_components if c in pivot_data.columns]]\n",
    "    corr_matrix = correlation_data.corr()\n",
    "    corr_matrix_with_labels = corr_matrix.reset_index()\n",
    "\n",
    "    # Rename the new first column\n",
    "    return corr_matrix_with_labels.rename(columns={\"index\": \"Components\"})"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d3db9c7601a1027a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.245403Z",
     "start_time": "2024-12-04T03:06:38.243576Z"
    }
   },
   "source": [
    "headerDimensions = {\n",
    "    'Datetime': 10,\n",
    "    'User_ID': 5,\n",
    "    'Component': 8,\n",
    "    'Action': 6,\n",
    "    'Target': 10,\n",
    "    'Month': 8,\n",
    "    'Year': 6,\n",
    "}\n",
    "\n",
    "\n",
    "def extract_data(df: pd.DataFrame):\n",
    "    headers = []\n",
    "    for col in df.columns:\n",
    "        dim = headerDimensions[col] if col in headerDimensions else 8\n",
    "        headers.append((col, dim))\n",
    "    return headers, df.values.tolist()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.250921Z",
     "start_time": "2024-12-04T03:06:38.247366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DbConn:\n",
    "    def __init__(self):\n",
    "        fp = Path(\"data\")\n",
    "        if not fp.exists():\n",
    "            fp.mkdir()\n",
    "\n",
    "        self.db_name = \"data/db.sqlite\"\n",
    "\n",
    "    def _connect(self):\n",
    "        return sqlite3.connect(self.db_name)\n",
    "\n",
    "    def save(self, df, table_name, if_exists='replace', index=False, chunksize=1000):\n",
    "        with self._connect() as conn:\n",
    "            df.to_sql(table_name, conn, if_exists=if_exists, index=index, chunksize=chunksize)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f'create index idx_datetime on {table_name} (Datetime)')\n",
    "            conn.commit()\n",
    "\n",
    "    def data_exists(self, table_name):\n",
    "        with self._connect() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f'select count(*) FROM {table_name}')\n",
    "            row_count = cursor.fetchone()[0]\n",
    "        return row_count > 0\n",
    "\n",
    "    def load(self, table_name, start, end):\n",
    "        suffix = ''\n",
    "        params = None\n",
    "        if start and end:\n",
    "            suffix = f' where Datetime between ? and ?'\n",
    "            params = (start.strftime('%Y-%m-%d %H:%M:%S'), end.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        with self._connect() as conn:\n",
    "            df = pd.read_sql(f'select * from {table_name}{suffix}', conn, params=params)\n",
    "        return df\n"
   ],
   "id": "7be267b36d516836",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:38.260650Z",
     "start_time": "2024-12-04T03:06:38.256439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def import_hook(files):\n",
    "    dataframes = []\n",
    "    try:\n",
    "        for file in files:\n",
    "            dataframes.append(pd.read_csv(file))\n",
    "    except Exception as e:\n",
    "        gui.set_status(\"File Read error: \" + str(e))\n",
    "        return\n",
    "\n",
    "    gui.toggle_loading_dialog(show=True)\n",
    "\n",
    "    user_log_df, activity_log_df, components_df = prep_df(dataframes)\n",
    "\n",
    "    if not transformation_remove(user_log_df, activity_log_df, components_df):\n",
    "        gui.set_status(\"Cleaning resulted in incompatible data types\")\n",
    "\n",
    "    transformation_rename(user_log_df, activity_log_df)\n",
    "\n",
    "    merged_df: pd.DataFrame = transformation_merge(user_log_df, activity_log_df)\n",
    "\n",
    "    start_date = merged_df[\"Datetime\"].min()\n",
    "    end_date = merged_df[\"Datetime\"].max()\n",
    "\n",
    "    db = DbConn()\n",
    "    db.save(merged_df, table_name=\"merged_data\")\n",
    "\n",
    "    apply_transformations(start_date, end_date)\n",
    "\n",
    "\n",
    "def check():\n",
    "    return DbConn().data_exists(\"merged_data\")\n",
    "\n",
    "\n",
    "def apply_transformations(start_date=None, end_date=None):\n",
    "    db = DbConn()\n",
    "    merged_df = db.load(\"merged_data\", start_date, end_date)\n",
    "    merged_df['Datetime'] = pd.to_datetime(merged_df['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if start_date is None:\n",
    "        start_date = merged_df[\"Datetime\"].min()\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = merged_df[\"Datetime\"].max()\n",
    "\n",
    "    gui.set_dates(start_date, end_date)\n",
    "\n",
    "    header, data = extract_data(merged_df)\n",
    "    gui.show_merge_data(header, data)\n",
    "\n",
    "    # monthly statistics\n",
    "    month_pivot_df = transformation_reshape(merged_df.copy(), \"Month\", period='M')\n",
    "\n",
    "    header, data = extract_data(month_pivot_df)\n",
    "    gui.show_pivot_data_month(header, data)\n",
    "\n",
    "    transformation_count(month_pivot_df, \"Month\")\n",
    "    monthly_stats = transformation_output_statistics(month_pivot_df, \"Month\")\n",
    "    header, data = extract_data(monthly_stats)\n",
    "    gui.show_stats_month(header, data)\n",
    "\n",
    "    # # total statistics\n",
    "    year_pivot_df = transformation_reshape(merged_df.copy(), \"Year\", period='Y')\n",
    "    header, data = extract_data(year_pivot_df)\n",
    "    gui.show_pivot_data_total(header, data)\n",
    "    year_stats = transformation_output_statistics(year_pivot_df, \"Year\")\n",
    "    header, data = extract_data(year_stats)\n",
    "    gui.show_stats_year(header, data)\n",
    "\n",
    "    corr_metrix = transformation_output_correlation(year_pivot_df)\n",
    "    header, data = extract_data(corr_metrix)\n",
    "    gui.show_corr(header, data)\n",
    "\n",
    "    gui.toggle_loading_dialog(show=False)\n",
    "\n",
    "\n"
   ],
   "id": "23508327f1e142d7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "aa79555aa3aa450c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:06:56.545787Z",
     "start_time": "2024-12-04T03:06:38.264758Z"
    }
   },
   "source": [
    "\n",
    "from gui import Gui\n",
    "\n",
    "gui = Gui(import_hook, check, apply_transformations)\n",
    "\n",
    "gui.mainloop()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summative",
   "language": "python",
   "name": "summative"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
